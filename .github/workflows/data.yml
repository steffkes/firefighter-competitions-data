on:
  workflow_dispatch:
  schedule:
    - cron: "*/10 * * * *"

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    defaults:
      run:
        working-directory: ./analysis
    steps:
      - uses: actions/checkout@v4
        with:
          ref: data-collection
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"
      - run: pip install -r requirements.txt
      - run: find spider/ -name "*rec*.py" | sort | jq -ncR '[inputs]' | jq -r  --arg date `date +'%y%m%d'` '.[] | . as $competition_spider | {competition_date: capture("(?<m>[[:digit:].]+)").m, $competition_spider} | select(.competition_date >= $date) | .competition_spider' | xargs -L1 scrapy runspider
      - run: scrapy runspider collector.py
      - uses: stefanzweifel/git-auto-commit-action@v4
        with:
          branch: data-collection
